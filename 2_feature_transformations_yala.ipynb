{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -q phonenumbers\n",
    "# !pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowpark for Python\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.version import VERSION\n",
    "import snowflake.snowpark.functions as F\n",
    "from snowflake.snowpark.types import DecimalType, StructType, StructField, DoubleType, StringType\n",
    "\n",
    "# Snowpark ML\n",
    "import snowflake.ml.modeling.preprocessing as snowml\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "from snowflake.ml.modeling.metrics.correlation import correlation\n",
    "\n",
    "from snowflake.ml.modeling.xgboost import XGBRegressor\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from snowflake.ml.modeling.model_selection import GridSearchCV\n",
    "from snowflake.ml.registry import model_registry\n",
    "from snowflake.ml._internal.utils import identifier\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# Data Science Libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from snowflake.ml.modeling.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Misc\n",
    "import json\n",
    "import joblib\n",
    "import cachetools\n",
    "\n",
    "# warning suppresion\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "import phonenumbers\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "## Connect to snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a Snowpark Connection\n",
    "\n",
    "connection_parameters = json.load(open('connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "\n",
    "snowflake_environment = session.sql('SELECT current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('\\nConnection Established with the following parameters:')\n",
    "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
    "print('Role                        : {}'.format(session.get_current_role()))\n",
    "print('Database                    : {}'.format(session.get_current_database()))\n",
    "print('Schema                      : {}'.format(session.get_current_schema()))\n",
    "print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the table name where we stored the diamonds dataset\n",
    "# **nChange this only if you named your table something else in the data ingest notebook **\n",
    "CONVERTEDONLY_LEADS_TABLE = 'CONVERTEDONLY'\n",
    "# TENTS_BY_LEADS_TABLE = 'TENTS_BY_LEAD'\n",
    "input_tbl1 = f\"{session.get_current_database()}.{session.get_current_schema()}.{CONVERTEDONLY_LEADS_TABLE}\"\n",
    "# input_tbl2 = f\"{session.get_current_database()}.{session.get_current_schema()}.{TENTS_BY_LEADS_TABLE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we read in the data from a Snowflake table into a Snowpark DataFrame\n",
    "leads_df = session.table(input_tbl1)\n",
    "# tents_df = session.table(input_tbl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leads_df.show()\n",
    "# tents_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fix_values(columnn):\n",
    "#     return F.upper(F.regexp_replace(F.col(columnn), '[^a-zA-Z0-9]+', '_'))\n",
    "\n",
    "# for col in [\"VALUE\"]:\n",
    "#     tents_df = tents_df.with_column(col, fix_values(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from snowflake.snowpark.functions import col, sum as sum_\n",
    "\n",
    "# # Apply OneHotEncoder\n",
    "# snowml_ohe = snowml.OneHotEncoder(input_cols=[\"VALUE\"], output_cols=['TNT'])\n",
    "# df_encoded = snowml_ohe.fit(tents_df).transform(tents_df)\n",
    "\n",
    "# # The OneHotEncoder might create new columns with specific names. \n",
    "# # Let's find out the names of these new columns.\n",
    "# new_columns = [c for c in df_encoded.columns if c not in tents_df.columns]\n",
    "\n",
    "# # Group by LEADID and aggregate\n",
    "# df_tents_grouped = df_encoded.groupBy(\"LEADID\").agg(*[sum_(col(c)).alias(c) for c in new_columns])\n",
    "  \n",
    "# # Show the result\n",
    "# df_tents_grouped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tents_grouped.write.mode('overwrite').save_as_table('tents_encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fix_values(columnn):\n",
    "#     return F.upper(F.regexp_replace(F.col(columnn), '[^a-zA-Z0-9]+', '_'))\n",
    "\n",
    "# for col in [\"ADDRESSCOUNTRY\"]:\n",
    "#     leads_df = leads_df.with_column(col, fix_values(col))\n",
    "\n",
    "# leads_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop features without values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df = leads_df.drop('SALUTATION'\n",
    ",'TITLE'\n",
    ",'FIRSTNAME'\n",
    ",'LASTNAME'\n",
    ",'WEBSITE'\n",
    ",'CONVERTEDCONTACTID'\n",
    ",'CONVERTEDDATE'\n",
    ",'CONVERTEDCONTACTID'\n",
    ",'CONVERTEDORGANIZATIONID'\n",
    ",'UPDATEDDATE'\n",
    ",'EMPLOYEECOUNT'\n",
    ",'LEADRATING'\n",
    ",'FAX'\n",
    ",'INDUSTRY'\n",
    ",'OWNERUSERID'\n",
    ",'RESPONSIBLEUSERID'\n",
    ",'ADDRESSSTREET'\n",
    ",'ADDRESSCITY'\n",
    ",'ADDRESSSTATE'\n",
    ",'ADDRESSPOSTCODE'\n",
    ",'LASTACTIVITYDATE'\n",
    ",'NEXTACTIVITYDATE'\n",
    ",'VISIBLETO'\n",
    ",'VISIBLETEAMID'\n",
    ",'ORGANIZATIONNAME'\n",
    ",'CREATEDUSERID'\n",
    ",'IMAGEURL'\n",
    ",'TAGS'\n",
    ",'O_ID'\n",
    ",'CONVERTED'\n",
    "# ,'CUSTOMFIELDS'\n",
    ",'LEADSTATUSID'\n",
    ",'MOBILE'\n",
    ",'PHONE'\n",
    ",'CONVERTEDOPPORTUNITYID')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Email with default value once empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values in the leads_df EMAIL dataframe column\n",
    "leads_df = leads_df.na.replace('', \"unknown@unknown.nl\", subset='EMAIL')\n",
    "# leads_df.write.mode('overwrite').save_as_table('tmp_leadsonly')\n",
    "# leads_df.show()\n",
    "print(leads_df.columns)\n",
    "leads_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new column with Email domain only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of identified private email domains\n",
    "private_domains = [\n",
    "    'gmail.com', 'hotmail.com', 'orange.fr', 'wanadoo.fr', 'hotmail.fr',\n",
    "    'yahoo.com', 'outlook.com', 'hotmail.co.uk', 'me.com', 'gmx.de',\n",
    "    'icloud.com', 'yahoo.it', 'libero.it', 'web.de', 'kpnmail.nl',\n",
    "    'yahoo.de', 'yahoo.fr', 'free.fr', 'telenet.be', 'live.fr',\n",
    "    'otenet.gr', 'mac.com', 'yahoo.co.uk', 'laposte.net', 'uol.com.br',\n",
    "    'casema.nl', 'aol.com', 't-online.de', 'unknown.com', 'yahoo.in',\n",
    "    'gmx.fr', 'mail.com', 'mail.ru', 'live.it', 'msn.com',\n",
    "    'yahoo.com.sg', 'hotmail.it', 'googlemail.com', 'hotmail.nl', 'ziggo.nl'\n",
    "]\n",
    "\n",
    "# Extracting the domain from the 'Email' column\n",
    "leads_df = leads_df.withColumn(\n",
    "    \"Email_Domain\",\n",
    "    F.regexp_extract(F.col(\"Email\"), '@([a-zA-Z0-9.-]+)$', 1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new column with tagging it as BUSINESS or PRIVATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying the email addresses as 'Private' or 'Business'\n",
    "# merged_data_prefixed['c_Email_Type'] = merged_data_prefixed['c_Email_Domain'].apply(\n",
    "#     lambda x: 'Private' if x in private_domains else 'Business')\n",
    "\n",
    "# Creating a column to classify email as 'Private' or 'Business'\n",
    "leads_df = leads_df.withColumn(\n",
    "    \"Email_Type\",\n",
    "    F.when(F.col(\"Email_Domain\").isin(private_domains), \"PRIVATE\").otherwise(\"BUSINESS\")\n",
    ")\n",
    "leads_df = leads_df.drop('EMAIL_DOMAIN')\n",
    "# leads_df.write.mode('overwrite').save_as_table('tmp_leadsonly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new column with the length of the lead description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column 'LENGTH_LEADDESCRIPTION' indicating the length of the text in 'LEADDESCRIPTION'\n",
    "leads_df = leads_df.withColumn(\"LENGTH_LEADDESCRIPTION\", F.length(F.col(\"LEADDESCRIPTION\")))\n",
    "leads_df = leads_df.drop('LEADDESCRIPTION')\n",
    "# print(leads_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values in the leads_df EMAIL dataframe column\n",
    "leads_df = leads_df.na.replace('-', \"NETHERLANDS\", subset='ADDRESSCOUNTRY')\n",
    "leads_df = leads_df.na.replace('', \"NETHERLANDS\", subset='ADDRESSCOUNTRY')\n",
    "leads_df = leads_df.na.replace('_', \"NETHERLANDS\", subset='ADDRESSCOUNTRY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract year, month, week, day, and hour from 'CreatedDate'\n",
    "# # Splitting 'CreatedDate' into Year, Month, Week, Day, and Hour portions with specified format\n",
    "\n",
    "# Assuming leads_df is your Snowflake DataFrame and 'CreatedDate' is a column in this DataFrame\n",
    "\n",
    "# Extracting year, month, week, day, and hour from 'CreatedDate'\n",
    "# Convert 'CreatedDate' to a timestamp type with the specified format\n",
    "leads_df = leads_df.withColumn('CreatedDate', F.to_timestamp('CreatedDate', 'MM/DD/YYYY HH12:MI:SS AM'))\n",
    "leads_df = leads_df.withColumn('CreatedYear', F.year('CreatedDate'))\n",
    "leads_df = leads_df.withColumn('CreatedMonth', F.month('CreatedDate'))\n",
    "leads_df = leads_df.withColumn('CreatedWeek', F.weekofyear('CreatedDate'))\n",
    "leads_df = leads_df.withColumn('CreatedDay', F.dayofweek('CreatedDate'))  # Note: In Snowflake, Sunday=0, Saturday=6\n",
    "leads_df = leads_df.withColumn('CreatedHour', F.hour('CreatedDate'))\n",
    "\n",
    "# Adjust 'CreatedDay' to make Monday=1, Sunday=7 if needed\n",
    "leads_df = leads_df.withColumn('CreatedDay', (F.col('CreatedDay') % 7) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(leads_df.columns)\n",
    "leads_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_values(columnn):\n",
    "    return F.upper(F.regexp_replace(F.col(columnn), '[^a-zA-Z0-9]+', '_'))\n",
    "\n",
    "for col in [\"ADDRESSCOUNTRY\"]:\n",
    "    leads_df = leads_df.with_column(col, fix_values(col))\n",
    "\n",
    "leads_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the length of the lead-description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the LEN_LEADDESC_NORM column\n",
    "snowml_mms = snowml.MinMaxScaler(input_cols=[\"LENGTH_LEADDESCRIPTION\"], output_cols=[\"LEN_LEADDESC_NORM\"])\n",
    "leads_df = snowml_mms.fit(leads_df).transform(leads_df)\n",
    "\n",
    "# Reduce the number of decimals\n",
    "new_col = leads_df.col(\"LEN_LEADDESC_NORM\").cast(DecimalType(7, 6))\n",
    "leads_df = leads_df.with_column(\"LEN_LEADDESC_NORM\", new_col)\n",
    "\n",
    "leads_df = leads_df.drop('LENGTH_LEADDESCRIPTION')\n",
    "leads_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colname in [\"LEN_LEADDESC_NORM\"]:\n",
    "    leads_df = leads_df.with_column(colname, leads_df[colname].cast(DoubleType()))\n",
    "\n",
    "leads_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns you do no longer need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df = leads_df.drop('CREATEDYEAR', 'CREATEDDATE', 'EMAIL')\n",
    "leads_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.write.mode(\"overwrite\").save_as_table(\"PRE_ENGINEERING_CONVERTEDONLY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure CUSTOMFIELDS is treated as JSON\n",
    "# leads_df = leads_df.withColumn(\"CUSTOMFIELDS_JSON\", F.parse_json(F.col(\"CUSTOMFIELDS\")))\n",
    "leads_df = leads_df.withColumn(\"CUSTOMFIELDS\", F.parse_json(F.col(\"CUSTOMFIELDS\")))\n",
    "\n",
    "# Flatten the JSON array to create individual rows for each JSON object\n",
    "flattened_df = leads_df.select(\n",
    "    F.col(\"ID\"),\n",
    "    F.flatten(F.col(\"CUSTOMFIELDS\")).alias(\"SEQ\", \"KEY\", \"PATH\", \"INDEX\", \"VALUE\", \"THIS\")\n",
    ")\n",
    "\n",
    "# Extract specific fields from the flattened JSON objects\n",
    "extracted_df = flattened_df.select(\n",
    "    F.col(\"ID\"),\n",
    "    F.col(\"VALUE\").getField(\"FIELD_NAME\").alias(\"FIELD_NAME\"),\n",
    "    F.col(\"VALUE\").getField(\"FIELD_VALUE\").alias(\"FIELD_VALUE\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter based on a specific FIELD_NAME, e.g., 'Tent_Type__c'\n",
    "filtered_df = extracted_df.filter(F.col(\"FIELD_NAME\") == \"Tent_Type__c\")\n",
    "\n",
    "# Now, filtered_df contains the rows where FIELD_NAME is 'Tent_Type__c'\n",
    "# and FIELD_VALUE contains the corresponding value\n",
    "\n",
    "# Show the result\n",
    "# filtered_df.show()\n",
    "\n",
    "# Split the FIELD_VALUE string into an array and explode it\n",
    "df_tent_types_exploded = filtered_df.withColumn(\"TENT_TYPE_ARRAY\", F.split(F.col(\"FIELD_VALUE\"), F.lit(\";\"))).select(\n",
    "    F.col(\"ID\"), \n",
    "    F.explode(F.col(\"TENT_TYPE_ARRAY\")).alias(\"TENT_TYPE\")\n",
    ")\n",
    "\n",
    "# Convert tent type values to uppercase\n",
    "df_tent_types_exploded = df_tent_types_exploded.withColumn(\"TENT_TYPE_UPPER\", F.upper(F.col(\"TENT_TYPE\")))\n",
    "\n",
    "# Apply One-Hot Encoding\n",
    "snowml_ohe = snowml.OneHotEncoder(input_cols=[\"TENT_TYPE_UPPER\"], output_cols=[\"TENT_TYPE_ENCODED\"])\n",
    "df_tent_types_encoded = snowml_ohe.fit(df_tent_types_exploded).transform(df_tent_types_exploded)\n",
    "\n",
    "# Replace spaces with underscores in the column names\n",
    "df_tent_types_encoded = df_tent_types_encoded.select(\n",
    "    *[F.col(col).alias(col.replace(\" \", \"_\")) for col in df_tent_types_encoded.columns]\n",
    ")\n",
    "\n",
    "# Dynamically generate the list of one-hot encoded column names with underscores\n",
    "encoded_column_names = [col for col in df_tent_types_encoded.columns if col.startswith(\"TENT_TYPE_ENCODED_\")]\n",
    "\n",
    "# Group by ID and aggregate the tent type columns\n",
    "df_tent_types_grouped = df_tent_types_encoded.groupBy(\"ID\").agg(\n",
    "    *[F.sum(F.col(col_name)).alias(col_name) for col_name in encoded_column_names]\n",
    ")\n",
    "\n",
    "# Join the transformed data back to the original DataFrame\n",
    "# df_final = leads_df.join(df_tent_types_grouped, \"ID\", \"left\")\n",
    "leads_df = leads_df.join(df_tent_types_grouped, \"ID\", \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the result\n",
    "# df_final.show()\n",
    "leads_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter based on a specific FIELD_NAME, e.g., 'Event__c'\n",
    "filtered_df = extracted_df.filter(F.col(\"FIELD_NAME\") == \"Event__c\")\n",
    "\n",
    "# Now, filtered_df contains the rows where FIELD_NAME is 'Event__c'\n",
    "# and FIELD_VALUE contains the corresponding value\n",
    "\n",
    "# Show the result\n",
    "# filtered_df.show()\n",
    "\n",
    "# Split the FIELD_VALUE string into an array and explode it\n",
    "df_events_exploded = filtered_df.withColumn(\"EVENT_ARRAY\", F.split(F.col(\"FIELD_VALUE\"), F.lit(\";\"))).select(\n",
    "    F.col(\"ID\"), \n",
    "    F.explode(F.col(\"EVENT_ARRAY\")).alias(\"EVENT\")\n",
    ")\n",
    "\n",
    "# Convert tent type values to uppercase\n",
    "df_events_exploded = df_events_exploded.withColumn(\"EVENT_UPPER\", F.upper(F.col(\"EVENT\")))\n",
    "\n",
    "# Apply One-Hot Encoding\n",
    "snowml_ohe = snowml.OneHotEncoder(input_cols=[\"EVENT_UPPER\"], output_cols=[\"EVENT_ENCODED\"])\n",
    "df_events_encoded = snowml_ohe.fit(df_events_exploded).transform(df_events_exploded)\n",
    "\n",
    "# Replace spaces with underscores in the column names\n",
    "df_events_encoded = df_events_encoded.select(\n",
    "    *[F.col(col).alias(col.replace(\" \", \"_\")) for col in df_events_encoded.columns]\n",
    ")\n",
    "\n",
    "# Dynamically generate the list of one-hot encoded column names with underscores\n",
    "encoded_column_names = [col for col in df_events_encoded.columns if col.startswith(\"EVENT_ENCODED_\")]\n",
    "\n",
    "# Group by ID and aggregate the tent type columns\n",
    "df_events_grouped = df_events_encoded.groupBy(\"ID\").agg(\n",
    "    *[F.sum(F.col(col_name)).alias(col_name) for col_name in encoded_column_names]\n",
    ")\n",
    "\n",
    "# Join the transformed data back to the original DataFrame\n",
    "# df_final = leads_df.join(df_events_grouped, \"ID\", \"left\")\n",
    "leads_df = leads_df.join(df_events_grouped, \"ID\", \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter based on a specific FIELD_NAME, e.g., 'Gender__c'\n",
    "filtered_df = extracted_df.filter(F.col(\"FIELD_NAME\") == \"Gender__c\")\n",
    "\n",
    "# Now, filtered_df contains the rows where FIELD_NAME is 'Gender__c'\n",
    "# and FIELD_VALUE contains the corresponding value\n",
    "\n",
    "# Show the result\n",
    "# filtered_df.show()\n",
    "\n",
    "# Split the FIELD_VALUE string into an array and explode it\n",
    "df_gender_exploded = filtered_df.withColumn(\"GENDER_ARRAY\", F.split(F.col(\"FIELD_VALUE\"), F.lit(\";\"))).select(\n",
    "    F.col(\"ID\"), \n",
    "    F.explode(F.col(\"GENDER_ARRAY\")).alias(\"GENDER\")\n",
    ")\n",
    "\n",
    "# Convert gender values to uppercase\n",
    "df_gender_exploded = df_gender_exploded.withColumn(\"GENDER_UPPER\", F.upper(F.col(\"GENDER\")))\n",
    "\n",
    "# Apply One-Hot Encoding\n",
    "snowml_ohe = snowml.OneHotEncoder(input_cols=[\"GENDER_UPPER\"], output_cols=[\"GENDER_ENCODED\"])\n",
    "df_gender_encoded = snowml_ohe.fit(df_gender_exploded).transform(df_gender_exploded)\n",
    "\n",
    "# Replace spaces with underscores in the column names\n",
    "df_gender_encoded = df_gender_encoded.select(\n",
    "    *[F.col(col).alias(col.replace(\" \", \"_\")) for col in df_gender_encoded.columns]\n",
    ")\n",
    "\n",
    "# Dynamically generate the list of one-hot encoded column names with underscores\n",
    "encoded_column_names = [col for col in df_gender_encoded.columns if col.startswith(\"GENDER_ENCODED_\")]\n",
    "\n",
    "# Group by ID and aggregate the gender columns\n",
    "df_gender_grouped = df_gender_encoded.groupBy(\"ID\").agg(\n",
    "    *[F.sum(F.col(col_name)).alias(col_name) for col_name in encoded_column_names]\n",
    ")\n",
    "\n",
    "# Join the transformed data back to the original DataFrame\n",
    "# df_final = leads_df.join(df_gender_grouped, \"ID\", \"left\")\n",
    "leads_df = leads_df.join(df_gender_grouped, \"ID\", \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'nan' values with 0 in all columns\n",
    "leads_df = leads_df.fillna(0)\n",
    "\n",
    "# Show the result\n",
    "leads_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering AND model preparation\n",
    "## One-hot encode \"LEADSOURCEID\", \"ADDRESSCOUNTRY\" and \"EMAIL_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categoricals to numeric columns\n",
    "snowml_ohe = snowml.OneHotEncoder(input_cols=[\"LEADSOURCEID\", \"ADDRESSCOUNTRY\", \"EMAIL_TYPE\"], output_cols=['LS', 'AD', 'ET'])\n",
    "# transformed_leads_df = snowml_ohe.fit(leads_df_snowflake).transform(leads_df_snowflake)\n",
    "leads_df = snowml_ohe.fit(leads_df).transform(leads_df)\n",
    "leads_df.show()\n",
    "\n",
    "# np.array(leads_df_snowflake.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns you do no longer need "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df = leads_df.drop('ID', 'LEADSOURCEID', 'ADDRESSCOUNTRY', 'EMAIL_TYPE', 'LENGTH_LEADDESCRIPTION', 'CUSTOMFIELDS')\n",
    "print(leads_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize all the features for modeling\n",
    "\n",
    "# Categorize all the features for processing\n",
    "NUMERICAL_COLUMNS = [\"CREATEDMONTH\", \"CREATEDWEEK\", \"CREATEDHOUR\", \"CREATEDDAY\", \"LEN_LEADDESC_NORM\"]\n",
    "\n",
    "LABEL_COLUMNS = ['O_OPPORTUNITYSTATE']\n",
    "OUTPUT_COLUMNS = ['PREDICTED_OPPORTUNITYSTATE']\n",
    "\n",
    "ONE_HOT_ENCODED_COLUMNS = [col for col in leads_df.columns\n",
    "                           if col.startswith(('LS_', 'AD_', 'ET_', 'TNT_', 'TENT_TYPE_ENCODED_', 'EVENT_ENCODED_', 'GENDER_ENCODED_'))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "leads_df_snowflake_train, leads_df_snowflake_test = leads_df.random_split(weights=[0.8, 0.2], seed=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the AI model xgb_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERSION WITH standard XGBOOST CLASSIFIER\n",
    "# Train\n",
    "# classifier.fit(train_df[FEATURE_COLUMNS], train_df[target_column])\n",
    "# classifier.fit(leads_df_snowflake_train[FEATURE_COLUMNS], leads_df_snowflake_train[target_column])\n",
    "# FEATURE_COLUMNS = NUMERICAL_COLUMNS + ONE_HOT_ENCODED_COLUMNS\n",
    "\n",
    "# leads_df_snowflake_train = leads_df_snowflake_train.to_pandas()\n",
    "# leads_df_snowflake_test = leads_df_snowflake_test.to_pandas()\n",
    "\n",
    "# X_train = leads_df_snowflake_train[FEATURE_COLUMNS]\n",
    "# y_train = leads_df_snowflake_train['O_OPPORTUNITYSTATE']\n",
    "\n",
    "# xgb_classifier = XGBClassifier()\n",
    "# xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Now fit the model\n",
    "# XGBClassifier.fit(leads_df_snowflake_train[FEATURE_COLUMNS], leads_df_snowflake_train['O_OPPORTUNITYSTATE'])\n",
    "\n",
    "# Predict\n",
    "# predictions = classifier.predict(leads_df_snowflake_test[FEATURE_COLUMNS])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERSION WITH Snowflake XGBOOST CLASSIFIER\n",
    "\n",
    "# Train\n",
    "# classifier.fit(train_df[FEATURE_COLUMNS], train_df[target_column])\n",
    "# classifier.fit(leads_df_snowflake_train[FEATURE_COLUMNS], leads_df_snowflake_train[target_column])\n",
    "FEATURE_COLUMNS = NUMERICAL_COLUMNS + ONE_HOT_ENCODED_COLUMNS\n",
    "\n",
    "# Define the XGBClassifier\n",
    "xgb_classifier = XGBClassifier(\n",
    "    input_cols=FEATURE_COLUMNS,\n",
    "    label_cols=LABEL_COLUMNS,\n",
    "    output_cols=OUTPUT_COLUMNS\n",
    ")\n",
    "\n",
    "xgb_classifier.fit(leads_df_snowflake_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use it to predict the Opportunitystate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = xgb_classifier.predict(leads_df_snowflake_test[FEATURE_COLUMNS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do some initial checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "# feature_importance = xgb_classifier.feature_importances_\n",
    "feature_importance = xgb_classifier.predict_proba(leads_df_snowflake_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'leads_df_snowflake_test' is your test dataset\n",
    "# and 'O_OPPORTUNITYSTATE' is the column with the true labels\n",
    "\n",
    "# y_test = leads_df_snowflake_test['O_OPPORTUNITYSTATE']\n",
    "\n",
    "# Calculate metrics\n",
    "# accuracy = accuracy_score(y_test, predictions)\n",
    "# precision = precision_score(y_test, predictions)\n",
    "# recall = recall_score(y_test, predictions)\n",
    "# f1 = f1_score(y_test, predictions)\n",
    "# conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Display metrics\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "# print(f'Precision: {precision}')\n",
    "# print(f'Recall: {recall}')\n",
    "# print(f'F1 Score: {f1}')\n",
    "# print(f'Confusion Matrix:\\n{conf_matrix}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming you have predictions and true labels\n",
    "# y_true = y_test  # Replace with your actual true labels\n",
    "# y_pred = predictions  # Replace with your model's predictions\n",
    "\n",
    "# Generate the confusion matrix\n",
    "# cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot using seaborn\n",
    "# sns.heatmap(cm, annot=True, fmt='d')\n",
    "# plt.ylabel('Actual')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier_ = xgb_classifier.to_xgboost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df_snowflake_test_pd = leads_df_snowflake_test.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SHAP explainer object\n",
    "explainer = shap.Explainer(xgb_classifier_)\n",
    "\n",
    "# Calculate SHAP values for the test set\n",
    "shap_values = explainer.shap_values(leads_df_snowflake_test_pd[FEATURE_COLUMNS])\n",
    "\n",
    "# Summarize the effects of all the features\n",
    "shap.summary_plot(shap_values, leads_df_snowflake_test_pd[FEATURE_COLUMNS])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for 'Won' and 'Lost' leads\n",
    "won_leads = leads_df[leads_df['O_OPPORTUNITYSTATE'] == 1]\n",
    "lost_leads = leads_df[leads_df['O_OPPORTUNITYSTATE'] == 0]\n",
    "\n",
    "won_leads = won_leads.to_pandas()\n",
    "lost_leads = lost_leads.to_pandas()\n",
    "\n",
    "# Assuming won_leads and lost_leads are pandas DataFrames with a column 'CREATEDWEEK'\n",
    "\n",
    "# Calculate the count of won and lost leads for each week\n",
    "week_counts_won = won_leads['CREATEDWEEK'].value_counts().sort_index()\n",
    "week_counts_lost = lost_leads['CREATEDWEEK'].value_counts().sort_index()\n",
    "\n",
    "# Ensure both series have the same weeks (in case some weeks are missing in either DataFrame)\n",
    "all_weeks = week_counts_won.index.union(week_counts_lost.index)\n",
    "week_counts_won = week_counts_won.reindex(all_weeks, fill_value=0)\n",
    "week_counts_lost = week_counts_lost.reindex(all_weeks, fill_value=0)\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = np.arange(len(all_weeks))\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Plot the 'Won' category\n",
    "plt.bar(x_pos, week_counts_won, align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' category on top of 'Won'\n",
    "plt.bar(x_pos, week_counts_lost, bottom=week_counts_won, align='center', alpha=0.7, color='red', label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Number of Leads')\n",
    "plt.title('Won vs Lost Leads by Week')\n",
    "plt.xticks(x_pos, all_weeks)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'won_leads' and 'lost_leads' are your datasets\n",
    "# and 'CREATEDWEEK' is the feature you're interested in\n",
    "\n",
    "# Define the bins for the histogram\n",
    "bins = np.arange(1, 55, 1)  # for weeks, from 0 to 52\n",
    "\n",
    "# Calculate histogram for Won and Lost leads\n",
    "hist_won, _ = np.histogram(won_leads['CREATEDWEEK'], bins=bins)\n",
    "hist_lost, _ = np.histogram(lost_leads['CREATEDWEEK'], bins=bins)\n",
    "\n",
    "# Calculate the total leads for each bin\n",
    "total_leads = hist_won + hist_lost\n",
    "\n",
    "# Avoid division by zero\n",
    "total_leads[total_leads == 0] = 1\n",
    "\n",
    "# Calculate percentages\n",
    "percent_won = (hist_won / total_leads) * 100\n",
    "percent_lost = (hist_lost / total_leads) * 100\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.bar(bins[:-1], percent_won, width=0.4, label='Won', align='center', color='green')\n",
    "plt.bar(bins[:-1], percent_lost, width=0.4, bottom=percent_won, label='Lost', align='center', color='red')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Percentage of Won and Lost Leads by Created Week (Stacked)')\n",
    "plt.legend()\n",
    "\n",
    "# Set x-axis ticks to show every week\n",
    "plt.xticks(bins[:-1])  # Set x-ticks to every week\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bin edges\n",
    "bins = np.arange(0, 1.1, 0.1)  # Creates an array from 0 to 1 with a step of 0.1\n",
    "# Filter the DataFrame for 'Won' and 'Lost' leads\n",
    "# won_leads = leads_df[leads_df['O_OPPORTUNITYSTATE'] == 1]\n",
    "# lost_leads = leads_df[leads_df['O_OPPORTUNITYSTATE'] == 0]\n",
    "\n",
    "# won_leads = won_leads.to_pandas()\n",
    "# lost_leads = lost_leads.to_pandas()\n",
    "\n",
    "# Calculate the histogram data for won and lost leads\n",
    "hist_won, _ = np.histogram(won_leads['LEN_LEADDESC_NORM'], bins=bins)\n",
    "hist_lost, _ = np.histogram(lost_leads['LEN_LEADDESC_NORM'], bins=bins)\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = (bins[:-1] + bins[1:]) / 2  # Midpoint of each bin\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the 'Won' category\n",
    "plt.bar(x_pos, hist_won, width=0.09, align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' category on top of 'Won'\n",
    "plt.bar(x_pos, hist_lost, width=0.09, bottom=hist_won, align='center', alpha=0.7, color='red', label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Normalized Lead Description Length')\n",
    "plt.ylabel('Number of Leads')\n",
    "plt.title('Won vs Lost Leads by Normalized Lead Description Length')\n",
    "plt.xticks(x_pos, labels=[f\"{round(b, 1)}-{round(b+0.1, 1)}\" for b in bins[:-1]])\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the bin edges\n",
    "bins = np.arange(0, 1.1, 0.1)  # Creates an array from 0 to 1 with a step of 0.1\n",
    "\n",
    "# Filter the DataFrame for 'Won' and 'Lost' leads\n",
    "won_leads = leads_df[leads_df['O_OPPORTUNITYSTATE'] == 1]\n",
    "lost_leads = leads_df[leads_df['O_OPPORTUNITYSTATE'] == 0]\n",
    "\n",
    "won_leads = won_leads.to_pandas()\n",
    "lost_leads = lost_leads.to_pandas()\n",
    "\n",
    "# Calculate the histogram data for won and lost leads\n",
    "hist_won, _ = np.histogram(won_leads['LEN_LEADDESC_NORM'], bins=bins)\n",
    "hist_lost, _ = np.histogram(lost_leads['LEN_LEADDESC_NORM'], bins=bins)\n",
    "\n",
    "# Calculate the total leads for each bin\n",
    "total_leads_per_bin = hist_won + hist_lost\n",
    "\n",
    "# Calculate the percentage of won and lost leads for each bin\n",
    "percentage_won = (hist_won / total_leads_per_bin) * 100\n",
    "percentage_lost = (hist_lost / total_leads_per_bin) * 100\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = (bins[:-1] + bins[1:]) / 2  # Midpoint of each bin\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the 'Won' category\n",
    "plt.bar(x_pos, percentage_won, width=0.09, align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' category on top of 'Won'\n",
    "plt.bar(x_pos, percentage_lost, width=0.09, bottom=percentage_won, align='center', alpha=0.7, color='red', label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Normalized Lead Description Length')\n",
    "plt.ylabel('Percentage of Leads')\n",
    "plt.title('Won vs Lost Leads by Normalized Lead Description Length (Percentage)')\n",
    "plt.xticks(x_pos, labels=[f\"{round(b, 1)}-{round(b+0.1, 1)}\" for b in bins[:-1]])\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for 'Won' and 'Lost' leads\n",
    "# won_leads = leads_df[leads_df['O_OPPORTUNITYSTATE'] == 1]\n",
    "# lost_leads = leads_df[leads_df['O_OPPORTUNITYSTATE'] == 0]\n",
    "\n",
    "# won_leads = won_leads.to_pandas()\n",
    "# lost_leads = lost_leads.to_pandas()\n",
    "\n",
    "# Assuming won_leads and lost_leads are pandas DataFrames with a column 'CREATEDHOUR'\n",
    "\n",
    "# Calculate the count of won and lost leads for each week\n",
    "hours_counts_won = won_leads['CREATEDHOUR'].value_counts().sort_index()\n",
    "hours_counts_lost = lost_leads['CREATEDHOUR'].value_counts().sort_index()\n",
    "\n",
    "# Ensure both series have the same weeks (in case some weeks are missing in either DataFrame)\n",
    "all_hours = hours_counts_won.index.union(hours_counts_lost.index)\n",
    "hours_counts_won = hours_counts_won.reindex(all_hours, fill_value=0)\n",
    "hours_counts_lost = hours_counts_lost.reindex(all_hours, fill_value=0)\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = np.arange(len(all_hours))\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the 'Won' category\n",
    "plt.bar(x_pos, hours_counts_won, align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' category on top of 'Won'\n",
    "plt.bar(x_pos, hours_counts_lost, bottom=hours_counts_won, align='center', alpha=0.7, color='red', label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Number of Leads')\n",
    "plt.title('Won vs Lost Leads by Hour')\n",
    "plt.xticks(x_pos, all_hours)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Filter the DataFrame for 'Won' and 'Lost' leads\n",
    "# won_leads = leads_df_snowflake[leads_df_snowflake['O_OPPORTUNITYSTATE'] == 1]\n",
    "# lost_leads = leads_df_snowflake[leads_df_snowflake['O_OPPORTUNITYSTATE'] == 0]\n",
    "\n",
    "# won_leads = won_leads.to_pandas()\n",
    "# lost_leads = lost_leads.to_pandas()\n",
    "\n",
    "# Calculate the count of won and lost leads for each hour\n",
    "hours_counts_won = won_leads['CREATEDHOUR'].value_counts().sort_index()\n",
    "hours_counts_lost = lost_leads['CREATEDHOUR'].value_counts().sort_index()\n",
    "\n",
    "# Ensure both series have the same hours (in case some hours are missing in either DataFrame)\n",
    "all_hours = hours_counts_won.index.union(hours_counts_lost.index)\n",
    "hours_counts_won = hours_counts_won.reindex(all_hours, fill_value=0)\n",
    "hours_counts_lost = hours_counts_lost.reindex(all_hours, fill_value=0)\n",
    "\n",
    "# Calculate the total leads for each hour\n",
    "total_leads_per_hour = hours_counts_won + hours_counts_lost\n",
    "\n",
    "# Calculate the percentage of won and lost leads for each hour\n",
    "percentage_won = (hours_counts_won / total_leads_per_hour) * 100\n",
    "percentage_lost = (hours_counts_lost / total_leads_per_hour) * 100\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = np.arange(len(all_hours))\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the 'Won' category\n",
    "plt.bar(x_pos, percentage_won, align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' category on top of 'Won'\n",
    "plt.bar(x_pos, percentage_lost, align='center', alpha=0.7, color='red', bottom=percentage_won, label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Percentage of Leads')\n",
    "plt.title('Won vs Lost Leads by Hour (Percentage)')\n",
    "plt.xticks(x_pos, all_hours)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Filter the DataFrame for 'Won' and 'Lost' leads\n",
    "# won_leads = leads_df_snowflake[leads_df_snowflake['O_OPPORTUNITYSTATE'] == 1]\n",
    "# lost_leads = leads_df_snowflake[leads_df_snowflake['O_OPPORTUNITYSTATE'] == 0]\n",
    "\n",
    "# won_leads = won_leads.to_pandas()\n",
    "# lost_leads = lost_leads.to_pandas()\n",
    "\n",
    "# Calculate the count of won and lost leads for each email type\n",
    "won_business = won_leads[won_leads['ET_BUSINESS'] == 1].shape[0]\n",
    "lost_business = lost_leads[lost_leads['ET_BUSINESS'] == 1].shape[0]\n",
    "\n",
    "won_private = won_leads[won_leads['ET_PRIVATE'] == 1].shape[0]\n",
    "lost_private = lost_leads[lost_leads['ET_PRIVATE'] == 1].shape[0]\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = np.arange(2)\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the 'Won' category for Business and Private\n",
    "plt.bar(x_pos, [won_business, won_private], align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' category on top of 'Won' for Business and Private\n",
    "plt.bar(x_pos, [lost_business, lost_private], bottom=[won_business, won_private], align='center', alpha=0.7, color='red', label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Email Type')\n",
    "plt.ylabel('Number of Leads')\n",
    "plt.title('Won vs Lost Leads by Email Type')\n",
    "plt.xticks(x_pos, ['ET_Business', 'ET_Private'])\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Filter the DataFrame for 'Won' and 'Lost' leads\n",
    "# won_leads = leads_df_snowflake[leads_df_snowflake['O_OPPORTUNITYSTATE'] == 1]\n",
    "# lost_leads = leads_df_snowflake[leads_df_snowflake['O_OPPORTUNITYSTATE'] == 0]\n",
    "\n",
    "# won_leads = won_leads.to_pandas()\n",
    "# lost_leads = lost_leads.to_pandas()\n",
    "\n",
    "# Calculate the count of won and lost leads for each email type\n",
    "won_business = won_leads[won_leads['ET_BUSINESS'] == 1].shape[0]\n",
    "lost_business = lost_leads[lost_leads['ET_BUSINESS'] == 1].shape[0]\n",
    "\n",
    "won_private = won_leads[won_leads['ET_PRIVATE'] == 1].shape[0]\n",
    "lost_private = lost_leads[lost_leads['ET_PRIVATE'] == 1].shape[0]\n",
    "\n",
    "# Calculate the total leads for each email type\n",
    "total_business = won_business + lost_business\n",
    "total_private = won_private + lost_private\n",
    "\n",
    "# Calculate the percentages\n",
    "percent_won_business = (won_business / total_business) * 100 if total_business > 0 else 0\n",
    "percent_lost_business = (lost_business / total_business) * 100 if total_business > 0 else 0\n",
    "\n",
    "percent_won_private = (won_private / total_private) * 100 if total_private > 0 else 0\n",
    "percent_lost_private = (lost_private / total_private) * 100 if total_private > 0 else 0\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = np.arange(2)\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the 'Won' percentage for Business and Private\n",
    "plt.bar(x_pos, [percent_won_business, percent_won_private], align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' percentage on top of 'Won' for Business and Private\n",
    "plt.bar(x_pos, [percent_lost_business, percent_lost_private], bottom=[percent_won_business, percent_won_private], align='center', alpha=0.7, color='red', label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Email Type')\n",
    "plt.ylabel('Percentage of Leads')\n",
    "plt.title('Won vs Lost Leads by Email Type (Percentage)')\n",
    "plt.xticks(x_pos, ['ET_Business', 'ET_Private'])\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for 'Won' and 'Lost' leads\n",
    "# won_leads = leads_df_snowflake[leads_df_snowflake['O_OPPORTUNITYSTATE'] == 1]\n",
    "# lost_leads = leads_df_snowflake[leads_df_snowflake['O_OPPORTUNITYSTATE'] == 0]\n",
    "\n",
    "# won_leads = won_leads.to_pandas()\n",
    "# lost_leads = lost_leads.to_pandas()\n",
    "\n",
    "# Assuming won_leads and lost_leads are pandas DataFrames with a column 'CREATEDHOUR'\n",
    "\n",
    "# Calculate the count of won and lost leads for each week\n",
    "months_counts_won = won_leads['CREATEDMONTH'].value_counts().sort_index()\n",
    "months_counts_lost = lost_leads['CREATEDMONTH'].value_counts().sort_index()\n",
    "\n",
    "# Ensure both series have the same weeks (in case some weeks are missing in either DataFrame)\n",
    "all_months = months_counts_won.index.union(months_counts_lost.index)\n",
    "months_counts_won = months_counts_won.reindex(all_months, fill_value=0)\n",
    "months_counts_lost = months_counts_lost.reindex(all_months, fill_value=0)\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = np.arange(len(all_months))\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the 'Won' category\n",
    "plt.bar(x_pos, months_counts_won, align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' category on top of 'Won'\n",
    "plt.bar(x_pos, months_counts_lost, bottom=months_counts_won, align='center', alpha=0.7, color='red', label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Months')\n",
    "plt.ylabel('Number of Leads')\n",
    "plt.title('Won vs Lost Leads by Month')\n",
    "plt.xticks(x_pos, all_months)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Filter the DataFrame for 'Won' and 'Lost' leads\n",
    "# won_leads = leads_df_snowflake[leads_df_snowflake['O_OPPORTUNITYSTATE'] == 1]\n",
    "# lost_leads = leads_df_snowflake[leads_df_snowflake['O_OPPORTUNITYSTATE'] == 0]\n",
    "\n",
    "# won_leads = won_leads.to_pandas()\n",
    "# lost_leads = lost_leads.to_pandas()\n",
    "\n",
    "# Calculate the count of won and lost leads for each month\n",
    "months_counts_won = won_leads['CREATEDMONTH'].value_counts().sort_index()\n",
    "months_counts_lost = lost_leads['CREATEDMONTH'].value_counts().sort_index()\n",
    "\n",
    "# Ensure both series have the same months\n",
    "all_months = months_counts_won.index.union(months_counts_lost.index)\n",
    "months_counts_won = months_counts_won.reindex(all_months, fill_value=0)\n",
    "months_counts_lost = months_counts_lost.reindex(all_months, fill_value=0)\n",
    "\n",
    "# Calculate the total leads for each month\n",
    "total_leads_per_month = months_counts_won + months_counts_lost\n",
    "\n",
    "# Calculate the percentages\n",
    "percent_won = (months_counts_won / total_leads_per_month) * 100\n",
    "percent_lost = (months_counts_lost / total_leads_per_month) * 100\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = np.arange(len(all_months))\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the 'Won' percentage for each month\n",
    "plt.bar(x_pos, percent_won, align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' percentage on top of 'Won' for each month\n",
    "plt.bar(x_pos, percent_lost, bottom=percent_won, align='center', alpha=0.7, color='red', label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Percentage of Leads')\n",
    "plt.title('Won vs Lost Leads by Month (Percentage)')\n",
    "plt.xticks(x_pos, all_months)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for 'Won' and 'Lost' leads\n",
    "# won_leads = leads_df_snowflake[leads_df_snowflake['O_OPPORTUNITYSTATE'] == 1]\n",
    "# lost_leads = leads_df_snowflake[leads_df_snowflake['O_OPPORTUNITYSTATE'] == 0]\n",
    "\n",
    "# won_leads = won_leads.to_pandas()\n",
    "# lost_leads = lost_leads.to_pandas()\n",
    "\n",
    "# Assuming won_leads and lost_leads are pandas DataFrames with a column 'CREATEDHOUR'\n",
    "\n",
    "# Calculate the count of won and lost leads for each week\n",
    "days_counts_won = won_leads['CREATEDDAY'].value_counts().sort_index()\n",
    "days_counts_lost = lost_leads['CREATEDDAY'].value_counts().sort_index()\n",
    "\n",
    "# Ensure both series have the same weeks (in case some weeks are missing in either DataFrame)\n",
    "all_days = days_counts_won.index.union(days_counts_lost.index)\n",
    "days_counts_won = days_counts_won.reindex(all_days, fill_value=0)\n",
    "days_counts_lost = days_counts_lost.reindex(all_days, fill_value=0)\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = np.arange(len(all_days))\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the 'Won' category\n",
    "plt.bar(x_pos, days_counts_won, align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' category on top of 'Won'\n",
    "plt.bar(x_pos, days_counts_lost, bottom=days_counts_won, align='center', alpha=0.7, color='red', label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Number of Leads')\n",
    "plt.title('Won vs Lost Leads by Day')\n",
    "plt.xticks(x_pos, all_days)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming won_leads and lost_leads are pandas DataFrames with a column 'CREATEDDAY'\n",
    "\n",
    "# Calculate the count of won and lost leads for each day\n",
    "days_counts_won = won_leads['CREATEDDAY'].value_counts().sort_index()\n",
    "days_counts_lost = lost_leads['CREATEDDAY'].value_counts().sort_index()\n",
    "\n",
    "# Ensure both series have the same days\n",
    "all_days = days_counts_won.index.union(days_counts_lost.index)\n",
    "days_counts_won = days_counts_won.reindex(all_days, fill_value=0)\n",
    "days_counts_lost = days_counts_lost.reindex(all_days, fill_value=0)\n",
    "\n",
    "# Calculate the total leads for each day\n",
    "total_leads_per_day = days_counts_won + days_counts_lost\n",
    "\n",
    "# Calculate the percentage of won and lost leads for each day\n",
    "percentage_won = (days_counts_won / total_leads_per_day) * 100\n",
    "percentage_lost = (days_counts_lost / total_leads_per_day) * 100\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = np.arange(len(all_days))\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the 'Won' category\n",
    "plt.bar(x_pos, percentage_won, align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' category on top of 'Won'\n",
    "plt.bar(x_pos, percentage_lost, bottom=percentage_won, align='center', alpha=0.7, color='red', label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Percentage of Leads')\n",
    "plt.title('Won vs Lost Leads by Day (Percentage)')\n",
    "plt.xticks(x_pos, all_days)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Retrieve the columns containing the country values\n",
    "country_columns = [col for col in leads_df.columns if col.startswith(('AD_'))]\n",
    "country_columns = [col.replace('\"', '') for col in country_columns]\n",
    "\n",
    "# Initialize dictionaries to store the counts\n",
    "won_counts = {country: won_leads[country].sum() for country in country_columns}\n",
    "lost_counts = {country: lost_leads[country].sum() for country in country_columns}\n",
    "\n",
    "# Calculate total leads per country and sort countries by total leads in descending order\n",
    "total_leads = {country: won_counts[country] + lost_counts[country] for country in country_columns}\n",
    "sorted_countries = sorted(total_leads, key=total_leads.get, reverse=True)\n",
    "\n",
    "# Update the counts based on the sorted order\n",
    "won_values = [won_counts[country] for country in sorted_countries]\n",
    "lost_values = [lost_counts[country] for country in sorted_countries]\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = np.arange(len(sorted_countries))\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot the 'Won' category for each country\n",
    "plt.bar(x_pos, won_values, align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' category on top of 'Won' for each country\n",
    "plt.bar(x_pos, lost_values, bottom=won_values, align='center', alpha=0.7, color='red', label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Number of Leads')\n",
    "plt.title('Won vs Lost Leads by Country')\n",
    "plt.xticks(x_pos, sorted_countries, rotation='vertical', fontsize=8)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Filter the DataFrame for 'Won' and 'Lost' leads\n",
    "# won_leads = leads_df_snowflake[leads_df_snowflake['O_OPPORTUNITYSTATE'] == 1]\n",
    "# lost_leads = leads_df_snowflake[leads_df_snowflake['O_OPPORTUNITYSTATE'] == 0]\n",
    "\n",
    "# won_leads = won_leads.to_pandas()\n",
    "# lost_leads = lost_leads.to_pandas()\n",
    "\n",
    "# Retrieve the columns containing the country values\n",
    "country_columns = [col for col in leads_df.columns if col.startswith(('AD_'))]\n",
    "country_columns = [col.replace('\"', '') for col in country_columns]\n",
    "\n",
    "# Initialize dictionaries to store the counts\n",
    "won_counts = {country: won_leads[country].sum() for country in country_columns}\n",
    "lost_counts = {country: lost_leads[country].sum() for country in country_columns}\n",
    "\n",
    "# Calculate total leads per country and sort countries by total leads in descending order\n",
    "total_leads = {country: won_counts[country] + lost_counts[country] for country in country_columns}\n",
    "sorted_countries = sorted(total_leads, key=total_leads.get, reverse=True)\n",
    "\n",
    "# Calculate the percentage of won and lost leads for each country\n",
    "won_percentages = [won_counts[country] / total_leads[country] * 100 if total_leads[country] > 0 else 0 for country in sorted_countries]\n",
    "lost_percentages = [lost_counts[country] / total_leads[country] * 100 if total_leads[country] > 0 else 0 for country in sorted_countries]\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = np.arange(len(sorted_countries))\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot the 'Won' percentage for each country\n",
    "plt.bar(x_pos, won_percentages, align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' percentage on top of 'Won' for each country\n",
    "plt.bar(x_pos, lost_percentages, bottom=won_percentages, align='center', alpha=0.7, color='red', label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Percentage of Leads')\n",
    "plt.title('Won vs Lost Leads by Country (Percentage)')\n",
    "plt.xticks(x_pos, sorted_countries, rotation='vertical', fontsize=8)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Filter the DataFrame for 'Won' and 'Lost' leads\n",
    "# won_leads = leads_df_snowflake[leads_df_snowflake['O_OPPORTUNITYSTATE'] == 1]\n",
    "# lost_leads = leads_df_snowflake[leads_df_snowflake['O_OPPORTUNITYSTATE'] == 0]\n",
    "\n",
    "# won_leads = won_leads.to_pandas()\n",
    "# lost_leads = lost_leads.to_pandas()\n",
    "\n",
    "# Retrieve the columns containing the lead source values\n",
    "leadsource_columns = [col for col in leads_df.columns if col.startswith(('LS_'))]\n",
    "\n",
    "# Initialize dictionaries to store the counts\n",
    "won_counts = {leadsource: won_leads[leadsource].sum() for leadsource in leadsource_columns}\n",
    "lost_counts = {leadsource: lost_leads[leadsource].sum() for leadsource in leadsource_columns}\n",
    "\n",
    "# Calculate total leads per lead source and sort lead sources by total leads in descending order\n",
    "total_leads = {leadsource: won_counts[leadsource] + lost_counts[leadsource] for leadsource in leadsource_columns}\n",
    "sorted_lead_sources = sorted(total_leads, key=total_leads.get, reverse=True)\n",
    "\n",
    "# Extract the counts for plotting\n",
    "won_values = [won_counts[leadsource] for leadsource in sorted_lead_sources]\n",
    "lost_values = [lost_counts[leadsource] for leadsource in sorted_lead_sources]\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = np.arange(len(sorted_lead_sources))\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot the 'Won' category for each lead source\n",
    "plt.bar(x_pos, won_values, align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' category on top of 'Won' for each lead source\n",
    "plt.bar(x_pos, lost_values, bottom=won_values, align='center', alpha=0.7, color='red', label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Lead Source')\n",
    "plt.ylabel('Number of Leads')\n",
    "plt.title('Won vs Lost Leads by Lead Source')\n",
    "plt.xticks(x_pos, sorted_lead_sources, rotation='vertical', fontsize=8)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# # Filter the DataFrame for 'Won' and 'Lost' leads\n",
    "# won_leads = leads_df_snowflake[leads_df_snowflake['O_OPPORTUNITYSTATE'] == 1]\n",
    "# lost_leads = leads_df_snowflake[leads_df_snowflake['O_OPPORTUNITYSTATE'] == 0]\n",
    "\n",
    "# won_leads = won_leads.to_pandas()\n",
    "# lost_leads = lost_leads.to_pandas()\n",
    "\n",
    "# Retrieve the columns containing the lead source values\n",
    "leadsource_columns = [col for col in leads_df.columns if col.startswith(('LS_'))]\n",
    "\n",
    "# Initialize dictionaries to store the counts and percentages\n",
    "won_counts = {leadsource: won_leads[leadsource].sum() for leadsource in leadsource_columns}\n",
    "lost_counts = {leadsource: lost_leads[leadsource].sum() for leadsource in leadsource_columns}\n",
    "\n",
    "# Calculate total leads per lead source and sort lead sources by total leads in descending order\n",
    "total_leads = {leadsource: won_counts[leadsource] + lost_counts[leadsource] for leadsource in leadsource_columns}\n",
    "sorted_lead_sources = sorted(total_leads, key=total_leads.get, reverse=True)\n",
    "\n",
    "# Calculate the percentage of won and lost leads for each lead source\n",
    "won_percentages = [won_counts[leadsource] / total_leads[leadsource] * 100 if total_leads[leadsource] > 0 else 0 for leadsource in sorted_lead_sources]\n",
    "lost_percentages = [lost_counts[leadsource] / total_leads[leadsource] * 100 if total_leads[leadsource] > 0 else 0 for leadsource in sorted_lead_sources]\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = np.arange(len(sorted_lead_sources))\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot the 'Won' percentage for each lead source\n",
    "plt.bar(x_pos, won_percentages, align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' percentage on top of 'Won' for each lead source\n",
    "plt.bar(x_pos, lost_percentages, bottom=won_percentages, align='center', alpha=0.7, color='red', label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Lead Source')\n",
    "plt.ylabel('Percentage of Leads')\n",
    "plt.title('Won vs Lost Leads by Lead Source (Percentage)')\n",
    "plt.xticks(x_pos, sorted_lead_sources, rotation='vertical', fontsize=8)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Retrieve the columns containing the tent type values\n",
    "tent_type_columns = [col for col in leads_df.columns if col.startswith('TENT_TYPE_ENCODED_')]\n",
    "tent_type_columns = [col.replace('\"', '') for col in tent_type_columns]\n",
    "\n",
    "# Initialize dictionaries to store the counts\n",
    "won_counts = {tent_type: won_leads[tent_type].sum() for tent_type in tent_type_columns}\n",
    "lost_counts = {tent_type: lost_leads[tent_type].sum() for tent_type in tent_type_columns}\n",
    "\n",
    "# Calculate total leads per tent type and sort tent types by total leads in descending order\n",
    "total_leads = {tent_type: won_counts[tent_type] + lost_counts[tent_type] for tent_type in tent_type_columns}\n",
    "sorted_tent_types = sorted(total_leads, key=total_leads.get, reverse=True)\n",
    "\n",
    "# Update the counts based on the sorted order\n",
    "won_values = [won_counts[tent_type] for tent_type in sorted_tent_types]\n",
    "lost_values = [lost_counts[tent_type] for tent_type in sorted_tent_types]\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = np.arange(len(sorted_tent_types))\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot the 'Won' category for each tent type\n",
    "plt.bar(x_pos, won_values, align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' category on top of 'Won' for each tent type\n",
    "plt.bar(x_pos, lost_values, bottom=won_values, align='center', alpha=0.7, color='red', label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Tent Type')\n",
    "plt.ylabel('Number of Leads')\n",
    "plt.title('Won vs Lost Leads by Tent Type')\n",
    "plt.xticks(x_pos, sorted_tent_types, rotation='vertical', fontsize=8)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Retrieve the columns containing the tent type values\n",
    "tent_type_columns = [col for col in leads_df.columns if col.startswith('TENT_TYPE_ENCODED_')]\n",
    "tent_type_columns = [col.replace('\"', '') for col in tent_type_columns]\n",
    "\n",
    "# Initialize dictionaries to store the counts\n",
    "won_counts = {tent_type: won_leads[tent_type].sum() for tent_type in tent_type_columns}\n",
    "lost_counts = {tent_type: lost_leads[tent_type].sum() for tent_type in tent_type_columns}\n",
    "\n",
    "# Calculate total leads per tent type and sort tent types by total leads in descending order\n",
    "total_leads = {tent_type: won_counts[tent_type] + lost_counts[tent_type] for tent_type in tent_type_columns}\n",
    "sorted_tent_types = sorted(total_leads, key=total_leads.get, reverse=True)\n",
    "\n",
    "# Calculate the percentage of won and lost leads for each tent type\n",
    "won_percentages = [won_counts[tent_type] / total_leads[tent_type] * 100 if total_leads[tent_type] > 0 else 0 for tent_type in sorted_tent_types]\n",
    "lost_percentages = [lost_counts[tent_type] / total_leads[tent_type] * 100 if total_leads[tent_type] > 0 else 0 for tent_type in sorted_tent_types]\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = np.arange(len(sorted_tent_types))\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot the 'Won' percentage for each tent type\n",
    "plt.bar(x_pos, won_percentages, align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' percentage on top of 'Won' for each tent type\n",
    "plt.bar(x_pos, lost_percentages, bottom=won_percentages, align='center', alpha=0.7, color='red', label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Tent Type')\n",
    "plt.ylabel('Percentage of Leads')\n",
    "plt.title('Won vs Lost Leads by Tent Type (Percentage)')\n",
    "plt.xticks(x_pos, sorted_tent_types, rotation='vertical', fontsize=8)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Retrieve the columns containing the event values\n",
    "event_columns = [col for col in leads_df.columns if col.startswith('EVENT_ENCODED_')]\n",
    "event_columns = [col.replace('\"', '') for col in event_columns]\n",
    "\n",
    "# Initialize dictionaries to store the counts\n",
    "won_counts = {event: won_leads[event].sum() for event in event_columns}\n",
    "lost_counts = {event: lost_leads[event].sum() for event in event_columns}\n",
    "\n",
    "# Calculate total leads per event and sort events by total leads in descending order\n",
    "total_leads = {event: won_counts[event] + lost_counts[event] for event in event_columns}\n",
    "sorted_events = sorted(total_leads, key=total_leads.get, reverse=True)\n",
    "\n",
    "# Update the counts based on the sorted order\n",
    "won_values = [won_counts[event] for event in sorted_events]\n",
    "lost_values = [lost_counts[event] for event in sorted_events]\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = np.arange(len(sorted_events))\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot the 'Won' category for each event\n",
    "plt.bar(x_pos, won_values, align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' category on top of 'Won' for each event\n",
    "plt.bar(x_pos, lost_values, bottom=won_values, align='center', alpha=0.7, color='red', label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Event')\n",
    "plt.ylabel('Number of Leads')\n",
    "plt.title('Won vs Lost Leads by Event')\n",
    "plt.xticks(x_pos, sorted_events, rotation='vertical', fontsize=8)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Retrieve the columns containing the event values\n",
    "event_columns = [col for col in leads_df.columns if col.startswith('EVENT_ENCODED_')]\n",
    "event_columns = [col.replace('\"', '') for col in event_columns]\n",
    "\n",
    "# Initialize dictionaries to store the counts\n",
    "won_counts = {event: won_leads[event].sum() for event in event_columns}\n",
    "lost_counts = {event: lost_leads[event].sum() for event in event_columns}\n",
    "\n",
    "# Calculate total leads per event and sort events by total leads in descending order\n",
    "total_leads = {event: won_counts[event] + lost_counts[event] for event in event_columns}\n",
    "sorted_events = sorted(total_leads, key=total_leads.get, reverse=True)\n",
    "\n",
    "# Calculate the percentage of won and lost leads for each event\n",
    "won_percentages = [won_counts[event] / total_leads[event] * 100 if total_leads[event] > 0 else 0 for event in sorted_events]\n",
    "lost_percentages = [lost_counts[event] / total_leads[event] * 100 if total_leads[event] > 0 else 0 for event in sorted_events]\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = np.arange(len(sorted_events))\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot the 'Won' percentage for each event\n",
    "plt.bar(x_pos, won_percentages, align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' percentage on top of 'Won' for each event\n",
    "plt.bar(x_pos, lost_percentages, bottom=won_percentages, align='center', alpha=0.7, color='red', label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Event')\n",
    "plt.ylabel('Percentage of Leads')\n",
    "plt.title('Won vs Lost Leads by Event (Percentage)')\n",
    "plt.xticks(x_pos, sorted_events, rotation='vertical', fontsize=8)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Retrieve the columns containing the gender values\n",
    "gender_columns = [col for col in leads_df.columns if col.startswith('GENDER_ENCODED_')]\n",
    "gender_columns = [col.replace('\"', '') for col in gender_columns]\n",
    "\n",
    "# Initialize dictionaries to store the counts\n",
    "won_counts = {gender: won_leads[gender].sum() for gender in gender_columns}\n",
    "lost_counts = {gender: lost_leads[gender].sum() for gender in gender_columns}\n",
    "\n",
    "# Calculate total leads per gender and sort genders by total leads in descending order\n",
    "total_leads = {gender: won_counts[gender] + lost_counts[gender] for gender in gender_columns}\n",
    "sorted_genders = sorted(total_leads, key=total_leads.get, reverse=True)\n",
    "\n",
    "# Update the counts based on the sorted order\n",
    "won_values = [won_counts[gender] for gender in sorted_genders]\n",
    "lost_values = [lost_counts[gender] for gender in sorted_genders]\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = np.arange(len(sorted_genders))\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot the 'Won' category for each gender\n",
    "plt.bar(x_pos, won_values, align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' category on top of 'Won' for each gender\n",
    "plt.bar(x_pos, lost_values, bottom=won_values, align='center', alpha=0.7, color='red', label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Number of Leads')\n",
    "plt.title('Won vs Lost Leads by Gender')\n",
    "plt.xticks(x_pos, sorted_genders, rotation='vertical', fontsize=8)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Retrieve the columns containing the gender values\n",
    "gender_columns = [col for col in leads_df.columns if col.startswith('GENDER_ENCODED_')]\n",
    "gender_columns = [col.replace('\"', '') for col in gender_columns]\n",
    "\n",
    "# Initialize dictionaries to store the counts\n",
    "won_counts = {gender: won_leads[gender].sum() for gender in gender_columns}\n",
    "lost_counts = {gender: lost_leads[gender].sum() for gender in gender_columns}\n",
    "\n",
    "# Calculate total leads per gender and sort genders by total leads in descending order\n",
    "total_leads = {gender: won_counts[gender] + lost_counts[gender] for gender in gender_columns}\n",
    "sorted_genders = sorted(total_leads, key=total_leads.get, reverse=True)\n",
    "\n",
    "# Calculate the percentage of won and lost leads for each gender\n",
    "won_percentages = [won_counts[gender] / total_leads[gender] * 100 if total_leads[gender] > 0 else 0 for gender in sorted_genders]\n",
    "lost_percentages = [lost_counts[gender] / total_leads[gender] * 100 if total_leads[gender] > 0 else 0 for gender in sorted_genders]\n",
    "\n",
    "# Create an array for the positions of the bars on the x-axis\n",
    "x_pos = np.arange(len(sorted_genders))\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot the 'Won' percentage for each gender\n",
    "plt.bar(x_pos, won_percentages, align='center', alpha=0.7, color='green', label='Won')\n",
    "\n",
    "# Plot the 'Lost' percentage on top of 'Won' for each gender\n",
    "plt.bar(x_pos, lost_percentages, bottom=won_percentages, align='center', alpha=0.7, color='red', label='Lost')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Percentage of Leads')\n",
    "plt.title('Won vs Lost Leads by Gender (Percentage)')\n",
    "plt.xticks(x_pos, sorted_genders, rotation='vertical', fontsize=8)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample input data to pass into the registry logging function\n",
    "# X = train_df.select(CATEGORICAL_COLUMNS_OE+NUMERICAL_COLUMNS).limit(100)\n",
    "X = leads_df_snowflake_test.select(FEATURE_COLUMNS).limit(20)\n",
    "# leads_df_snowflake_test_pd\n",
    "\n",
    "db = identifier._get_unescaped_name(session.get_current_database())\n",
    "schema = identifier._get_unescaped_name(session.get_current_schema())\n",
    "\n",
    "# Define model name and version\n",
    "model_name = \"leads_model\"\n",
    "model_version = 1\n",
    "\n",
    "# Create a registry and log the model\n",
    "registry = model_registry.ModelRegistry(session=session, database_name=db, schema_name=schema, create_if_not_exists=True)\n",
    "\n",
    "registry.log_model(\n",
    "    model_name=model_name,\n",
    "    model_version=model_version,\n",
    "    model=xgb_classifier,\n",
    "    sample_input_data=X,\n",
    "    options={\"embed_local_ml_library\": True, # This option is enabled to pull latest dev code changes.\n",
    "             \"relax\": True} # relax dependencies\n",
    ")\n",
    "\n",
    "# Add evaluation metric\n",
    "# registry.set_metric(model_name=model_name, model_version=model_version, metric_name=\"mean_abs_pct_err\", metric_value=optimal_mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's confirm it was added\n",
    "# registry.list_models().to_pandas()\n",
    "registry.list_deployments(model_name, model_version).to_pandas()\n",
    "# print(model_name)\n",
    "# print(model_deployment_name)\n",
    "# print(model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a deployment name and deploy\n",
    "model_deployment_name = model_name + f\"{model_version}\" + \"_UDF\"\n",
    "\n",
    "registry.deploy(model_name=model_name,\n",
    "                model_version=model_version,\n",
    "                deployment_name=model_deployment_name, \n",
    "                target_method=\"predict\", \n",
    "                permanent=True, \n",
    "                options={\"relax_version\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can always get a reference to our registry using this function call\n",
    "model_ref = model_registry.ModelReference(registry=registry, model_name=model_name, model_version=model_version)\n",
    "\n",
    "# We can then use the deployed model to perform inference\n",
    "result_sdf = model_ref.predict(deployment_name=model_deployment_name, data=leads_df_snowflake_test)\n",
    "\n",
    "# result_sdf.rename(F.col('\"output_feature_0\"'),\"PREDICTED_PRICE\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df_snowflake_test_reordered = leads_df_snowflake_test[FEATURE_COLUMNS]\n",
    "# instance_to_explain = leads_df_snowflake_test_reordered[FEATURE_COLUMNS].iloc[0]\n",
    "instance_to_explain = leads_df_snowflake_test_reordered[FEATURE_COLUMNS].to_pandas().iloc[11]\n",
    "# Assuming instance_to_explain is a Pandas Series\n",
    "instance_array = instance_to_explain.values.reshape(1, -1)\n",
    "# Calculate SHAP values for this instance\n",
    "shap_values_instance = explainer.shap_values(instance_array)\n",
    "# Visualize the first prediction's explanation\n",
    "shap.force_plot(explainer.expected_value, shap_values_instance, instance_to_explain)\n",
    "# shap.summary_plot(explainer.expected_value, shap_values_instance, instance_to_explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_to_explain.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming xgb_classifier is your trained model and instance_to_explain is your data instance\n",
    "# Reshape the instance data if necessary\n",
    "instance_data = instance_to_explain.values.reshape(1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model's prediction for this instance\n",
    "final_prediction = xgb_classifier.to_xgboost().predict(instance_data)\n",
    "final_prediction_proba = xgb_classifier.to_xgboost().predict_proba(instance_data)\n",
    "\n",
    "print(\"Final Prediction for the instance:\", final_prediction)\n",
    "print(\"Final Prediction for the instance:\", final_prediction_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the decision plot\n",
    "shap.decision_plot(explainer.expected_value, shap_values[26], instance_to_explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Base value (expected value):\", explainer.expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the SHAP values for the instance into a DataFrame for easier interpretation\n",
    "# shap_values_df = pd.DataFrame(shap_values_instance, columns=FEATURE_COLUMNS)\n",
    "\n",
    "# Display the DataFrame\n",
    "# print(shap_values_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = xgb_classifier.predict_proba(instance_data)\n",
    "print(\"Probabilities for the instance:\", probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'xgb_classifier' is your trained XGBoost model\n",
    "# and 'instance_to_explain' is the specific instance you want to explain\n",
    "\n",
    "# Get the probability output for the instance\n",
    "probabilities = xgb_classifier.predict_proba(instance_to_explain.values.reshape(1, -1))\n",
    "\n",
    "# Print the probabilities\n",
    "print(probabilities)\n",
    "# print(instance_to_explain.to_csv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model clean up code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "# registry.delete_deployment(model_name=model_name, model_version=model_version, deployment_name=model_deployment_name)\n",
    "# registry.delete_model(model_name=model_name, model_version=model_version, delete_artifact=True)\n",
    "# Let's confirm it was deleted\n",
    "# registry.list_deployments(model_name, model_version).to_pandas()\n",
    "# registry.list_models().to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowpark-ml-hol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
